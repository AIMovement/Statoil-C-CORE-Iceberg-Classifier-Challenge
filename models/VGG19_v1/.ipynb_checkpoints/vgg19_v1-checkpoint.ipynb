{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, concatenate, Input\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create VGG19+ Fully connected layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n"
     ]
    }
   ],
   "source": [
    "# Import ResNet pretrained model\n",
    "model = VGG19(weights='imagenet', include_top=False, input_shape = (225, 225, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding custom Layers \n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(inputs = model.input, outputs = predictions)\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(df):\n",
    "    images = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        band_1 = np.array(row['band_1']).reshape(75, 75)\n",
    "        band_2 = np.array(row['band_2']).reshape(75, 75)\n",
    "        \n",
    "        #band_1 *= np.arccos(row['inc_angle'])\n",
    "        #band_2 *= np.arccos(row['inc_angle'])\n",
    "        \n",
    "        # Bilinear interpolation\n",
    "        band_1 = zoom(band_1, 3, order=1)\n",
    "        band_2 = zoom(band_2, 3, order=1)\n",
    "        band_3 = band_2 - band_1\n",
    "        \n",
    "        X = np.dstack((band_1, band_2, band_3))\n",
    "\n",
    "        #X = np.expand_dims(X, axis=0)\n",
    "        #X = preprocess_input(X)\n",
    "        \n",
    "        images.append(X)\n",
    "        \n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "def get_angles(df):\n",
    "    angles = []\n",
    "    max_angle = df['inc_angle'].max()\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        angle = np.array(row['inc_angle'])\n",
    "        \n",
    "        # Pre-Processing:\n",
    "        #  - ...\n",
    "        \n",
    "        #angle /= max_angle\n",
    "        \n",
    "        angles.append(angle)\n",
    "        \n",
    "    return np.array(angles)\n",
    "\n",
    "\n",
    "def plot_acc(histobj):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.plot(histobj.history['acc'])\n",
    "    plt.plot(histobj.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_loss(histobj):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.plot(histobj.history['loss'])\n",
    "    plt.plot(histobj.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "      \n",
    "    \n",
    "def show_image(img):\n",
    "    fig = plt.figure(figsize=(12, 5))\n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "    ax.imshow(img[:, :, 0], cmap=cm.inferno)\n",
    "    ax.set_title('Band 1')\n",
    "\n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    im = ax.imshow(img[:, :, 1], cmap=cm.inferno)\n",
    "    ax.set_title('Band 2')\n",
    "    \n",
    "    cax = fig.add_axes([0.95, 0.1, 0.03, 0.8])\n",
    "    fig.colorbar(im, cax=cax, label='[dB]')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def get_class(pred, label, img):\n",
    "    classes = ['ship', 'iceberg']\n",
    "    pred_i = np.argmax(pred)\n",
    "    label_i = np.argmax(label)\n",
    "    print('Prediction class = {}'.format(classes[pred_i]))\n",
    "    print('Prediction value (%) = {}'.format(pred[pred_i]))\n",
    "    print('Label class = {}'.format(classes[label_i]))\n",
    "    show_image(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_json(\n",
    "    'C:/Users/okarnbla/Documents/private_repos/Kaggle/iceberg_classifier/data/train.json', dtype='float32')\n",
    "test_df = pd.read_json(\n",
    "    'C:/Users/okarnbla/Documents/private_repos/Kaggle/iceberg_classifier/data/test.json', dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop N/A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df['inc_angle'] != 'na']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = 100\n",
    "train_ran_df = train_df.sample(frac=1, random_state=state)\n",
    "train_ran_df = train_ran_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_images(train_ran_df)\n",
    "print(X.shape)\n",
    "Y = to_categorical(train_ran_df.is_iceberg.values, num_classes=2) # [0. 1.]=iceberg, [1. 0.]=ship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = get_images(test_df)\n",
    "X_ids = test_df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:,0,0,0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = np.round(0.8*(X[:,0,0,0].shape[0]))\n",
    "train_samples = np.int(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[0:train_samples]\n",
    "Y_train = Y[0:train_samples]\n",
    "\n",
    "X_val = X[train_samples+1:-1]\n",
    "Y_val = Y[train_samples+1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hist = model_final.fit(X_train, Y_train, validation_data=(X_val, Y_val), batch_size=32, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(model_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc(model_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model_final.predict(X_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 30\n",
    "get_class(val_preds[sample], val_Y[sample], val_X[sample])\n",
    "is_ice = test_preds[:, 1]\n",
    "ids = TEST_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('subv3.csv', 'w') as fp:\n",
    "    fp.write('id,is_iceberg\\n')\n",
    "    for i in range(len(X_ids)):\n",
    "        fp.write('{0:},{1:.10f}\\n'.format(X_ids[i], test_preds[i,1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
